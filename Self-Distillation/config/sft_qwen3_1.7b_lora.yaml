defaults:
  - sft_config  # Inherit from base SFT config
  - _self_

model:
  name: "Qwen/Qwen3-1.7B"
  torch_dtype: "bfloat16"
  use_flash_attention: false
  lora:
    r: 64
    lora_alpha: 16
    target_modules: "all-linear"
    lora_dropout: 0.1
    bias: "none"
    task_type: "CAUSAL_LM"

training:
  output_dir: "outputs/sft-qwen3-1.7b"
  per_device_train_batch_size: 32
  gradient_accumulation_steps: 1

wandb:
  project: "self-distillation"
  run_name: "qwen3-1.7b-sft-lora"
